{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8xdsIg2skEY"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import time\n",
        "import math\n",
        "import statistics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import (\n",
        "    RandomizedSearchCV, GridSearchCV, cross_val_score,\n",
        "    StratifiedKFold, RepeatedStratifiedKFold, cross_validate\n",
        ")\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.ensemble import (\n",
        "    VotingClassifier, StackingClassifier\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, recall_score, precision_score, f1_score,\n",
        "    roc_auc_score, matthews_corrcoef, make_scorer, get_scorer\n",
        ")\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDwotRckD7As"
      },
      "outputs": [],
      "source": [
        "DetDF = pd.DataFrame (columns = ['Classifier', 'Accuracy', 'Recall', 'Precision', 'F1 score', 'AUC', 'MCC', 'Time', 'Dataset'])\n",
        "ResDF = pd.DataFrame (columns = ['Classifier', 'Accuracy', 'Recall', 'Precision', 'F1 score', 'AUC', 'MCC', 'Time', 'Dataset'])\n",
        "StaDF = pd.DataFrame (columns = ['Classifier_1', 'Classifier_2', 'Stat', 'Sig-level', 'p-value', 'Null Hypo', 'Win', 'Lost', 'Effect Size', 'Effect Type', 'Dataset'])\n",
        "\n",
        "smell_datasets = ['Large Class.csv', 'Long Method.csv', 'Long Base Class List.csv', 'Long Parameter List.csv', 'Long Scope Chaining.csv']\n",
        "\n",
        "fnames = smell_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TQjqMhNay5x"
      },
      "outputs": [],
      "source": [
        "class FS_GainRatio(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, num_features=1):\n",
        "        self.num_features = num_features\n",
        "        self.selected_features = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        info_gain = mutual_info_classif(X, y)\n",
        "        intrinsic_value = -np.nansum((X / np.sum(X, axis=0)) * np.log2(X / np.sum(X, axis=0)), axis=0)\n",
        "        intrinsic_value[intrinsic_value == 0] = np.finfo(float).eps\n",
        "        gain_ratio_scores = info_gain / intrinsic_value\n",
        "        mean_score = np.mean(gain_ratio_scores)\n",
        "        self.selected_features = [i for i in np.argsort(gain_ratio_scores)[::-1] if gain_ratio_scores[i] >= mean_score]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[:, self.selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMiU1EA2ckkN"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "selector = FS_GainRatio()\n",
        "\n",
        "inner_cv = StratifiedKFold(n_splits=5)\n",
        "outer_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10)\n",
        "n_jobs = -1\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'recall': make_scorer(recall_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'roc_auc': make_scorer(roc_auc_score),\n",
        "    'mcc': make_scorer(matthews_corrcoef)\n",
        "}\n",
        "\n",
        "ml_param_grids = {\n",
        "    'DT': {\n",
        "        'dt__criterion': ['gini', 'entropy'],\n",
        "        'dt__max_depth': [None, 5, 10, 20, 30],\n",
        "        'dt__min_samples_split': [2, 5, 10],\n",
        "        'dt__min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    'KNN': {\n",
        "        'knn__n_neighbors': [3, 5, 7, 10],\n",
        "        'knn__weights': ['uniform', 'distance'],\n",
        "        'knn__metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "    },\n",
        "    'LR': {\n",
        "        'lr__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'lr__solver': ['lbfgs', 'liblinear'],\n",
        "        'lr__penalty': ['l2']\n",
        "    },\n",
        "    'SVM': {\n",
        "        'svm__C': [0.1, 1, 10, 100],\n",
        "        'svm__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "        'svm__gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'MLP': {\n",
        "        'mlp__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
        "        'mlp__activation': ['relu', 'tanh'],\n",
        "        'mlp__solver': ['adam', 'sgd'],\n",
        "        'mlp__alpha': [0.0001, 0.001, 0.01]\n",
        "    },\n",
        "    'SGD': {\n",
        "        'sgd__penalty': ['l2', 'l1', 'elasticnet'],\n",
        "        'sgd__alpha': [0.0001, 0.001, 0.01],\n",
        "        'sgd__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
        "        'sgd__eta0': [0.01, 0.1, 1, 10]  # Adding valid eta0 values\n",
        "    },\n",
        "    'NB': {\n",
        "        'nb__var_smoothing': np.logspace(-10, -2, 50)\n",
        "    },\n",
        "    'GP': {\n",
        "        'gp__kernel': [1.0 * RBF(length_scale) for length_scale in [0.1, 1, 10]]\n",
        "    }\n",
        "}\n",
        "\n",
        "ml_pipelines = {\n",
        "    'DT': Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('selector', selector),\n",
        "        ('dt', DecisionTreeClassifier())\n",
        "    ]),\n",
        "    'KNN': Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('selector', selector),\n",
        "        ('knn', KNeighborsClassifier())\n",
        "    ]),\n",
        "    'LR': Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('selector', selector),\n",
        "        ('lr', LogisticRegression())\n",
        "    ]),\n",
        "    'SVM': Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('selector', selector),\n",
        "        ('svm', SVC(probability=True))\n",
        "    ]),\n",
        "    'MLP': Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('selector', selector),\n",
        "        ('mlp', MLPClassifier())\n",
        "    ]),\n",
        "    'SGD': Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('selector', selector),\n",
        "        ('sgd', SGDClassifier(loss='log_loss'))\n",
        "    ]),\n",
        "    'NB': Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('selector', selector),\n",
        "        ('nb', GaussianNB())\n",
        "    ]),\n",
        "    'GP': Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('selector', selector),\n",
        "        ('gp', GaussianProcessClassifier())\n",
        "    ])\n",
        "}\n",
        "\n",
        "ml_models = []\n",
        "for name, pipeline in ml_pipelines.items():\n",
        "    ml_models.append([name, RandomizedSearchCV(pipeline, ml_param_grids.get(name, {}), cv=inner_cv, scoring='matthews_corrcoef', refit=True, n_jobs=n_jobs)])\n",
        "\n",
        "hard_voting = VotingClassifier(estimators=ml_models, voting='hard', n_jobs=n_jobs)\n",
        "soft_voting = VotingClassifier(estimators=ml_models, voting='soft', n_jobs=n_jobs)\n",
        "stacking = StackingClassifier(estimators=ml_models, n_jobs=n_jobs)\n",
        "\n",
        "ensemble_models = [\n",
        "    ('Hard Voting', hard_voting),\n",
        "    ('Soft Voting', soft_voting),\n",
        "    ('Stacking', stacking)\n",
        "]\n",
        "\n",
        "dl_models = [\n",
        "    ('CNN', ''),\n",
        "    ('LSTM', ''),\n",
        "    ('GRU', '')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Conv1D, Dense, Flatten, Dropout, MaxPooling1D, Input, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "kf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10)\n",
        "\n",
        "def compute_scores(y_true, y_pred_prob, threshold=0.5):\n",
        "    y_pred = (y_pred_prob > threshold).astype(int)\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
        "        'roc_auc': roc_auc_score(y_true, y_pred_prob),\n",
        "        'mcc': matthews_corrcoef(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "def build_deep_models(X, y):\n",
        "    global DetDF, ResDF\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Define models with improved regularization and dropout\n",
        "    models = {\n",
        "        \"LSTM\": Sequential([\n",
        "            Input(shape=(X.shape[1], 1)),\n",
        "            LSTM(16, return_sequences=True, kernel_regularizer=l2(0.005)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.4),\n",
        "            LSTM(8, kernel_regularizer=l2(0.005)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.4),\n",
        "            Dense(1, activation='sigmoid', kernel_regularizer=l2(0.005))\n",
        "        ]),\n",
        "        \"CNN\": Sequential([\n",
        "            Input(shape=(X.shape[1], 1)),\n",
        "            Conv1D(filters=16, kernel_size=3, activation='relu', kernel_regularizer=l2(0.005)),\n",
        "            BatchNormalization(),\n",
        "            MaxPooling1D(pool_size=2),\n",
        "            Flatten(),\n",
        "            Dense(8, activation='relu', kernel_regularizer=l2(0.005)),\n",
        "            Dropout(0.4),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ]),\n",
        "        \"GRU\": Sequential([\n",
        "            Input(shape=(X.shape[1], 1)),\n",
        "            GRU(16, return_sequences=True, kernel_regularizer=l2(0.005)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.4),\n",
        "            GRU(8, kernel_regularizer=l2(0.005)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.4),\n",
        "            Dense(1, activation='sigmoid', kernel_regularizer=l2(0.005))\n",
        "        ])\n",
        "    }\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        fold_results = []\n",
        "        for train_index, test_index in kf.split(X, y):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            X_train = np.expand_dims(X_train, axis=-1)\n",
        "            X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "            model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "            lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=0)\n",
        "\n",
        "            start_time = time.time()\n",
        "            model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0, validation_data=(X_test, y_test),\n",
        "                      callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "            y_pred_prob = model.predict(X_test).flatten()\n",
        "\n",
        "            elapsed_time = time.time() - start_time\n",
        "\n",
        "            scores = compute_scores(y_test, y_pred_prob)\n",
        "            fold_result = {\n",
        "                'Classifier': model_name,\n",
        "                'Accuracy': scores['accuracy'],\n",
        "                'Recall': scores['recall'],\n",
        "                'Precision': scores['precision'],\n",
        "                'F1 score': scores['f1'],\n",
        "                'AUC': scores['roc_auc'],\n",
        "                'MCC': scores['mcc'],\n",
        "                'Time': elapsed_time,\n",
        "                'Dataset': fname\n",
        "            }\n",
        "            DetDF = pd.concat([DetDF, pd.DataFrame([fold_result])], ignore_index=True)\n",
        "            fold_results.append(fold_result)\n",
        "\n",
        "        avg_results = pd.DataFrame(fold_results).mean(numeric_only=True).to_dict()\n",
        "        avg_results['Classifier'] = model_name\n",
        "        ResDF = pd.concat([ResDF, pd.DataFrame([avg_results])], ignore_index=True)\n",
        "\n",
        "    return models"
      ],
      "metadata": {
        "id": "O_Vuzjb3JkD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in fnames:\n",
        "    print(\"Dataset = \" + fname)\n",
        "\n",
        "    data = pd.read_csv(fname)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    X = data.drop(columns=[\"class\"]).values\n",
        "    y = data[\"class\"].values\n",
        "\n",
        "    build_deep_models(X,y)\n",
        "\n",
        "    for name, model in ml_models:\n",
        "        print(\"Processing Model = \" + name)\n",
        "        cv_results = cross_validate(model, X, y, cv=outer_cv, scoring=scoring, n_jobs=n_jobs, return_estimator=False)\n",
        "        results[name] = cv_results\n",
        "\n",
        "    for name, model in ensemble_models:\n",
        "        print(\"Processing Model = \" + name)\n",
        "        cv_results = cross_validate(model, X, y, cv=outer_cv, scoring=scoring, n_jobs=n_jobs, return_estimator=False)\n",
        "        results[name] = cv_results\n",
        "\n",
        "    for name, _ in ml_models + ensemble_models:\n",
        "        result = results[name]\n",
        "\n",
        "        acc_scores = result['test_accuracy']\n",
        "        rec_scores = result['test_recall']\n",
        "        pre_scores = result['test_precision']\n",
        "        f1s_scores = result['test_f1']\n",
        "        auc_scores = result['test_roc_auc']\n",
        "        mcc_scores = result['test_mcc']\n",
        "        test_times = result['score_time'] + result['fit_time']  # Total time = fit + score time\n",
        "\n",
        "        new_row = {'Classifier': name,\n",
        "                   'Accuracy': np.round(acc_scores.mean(), 2),\n",
        "                   'Recall': np.round(rec_scores.mean(), 2),\n",
        "                   'Precision': np.round(pre_scores.mean(), 2),\n",
        "                   'F1 score': np.round(f1s_scores.mean(), 2),\n",
        "                   'AUC': np.round(auc_scores.mean(), 2),\n",
        "                   'MCC': np.round(mcc_scores.mean(), 2),\n",
        "                   'Time': np.round(test_times.mean(), 2),\n",
        "                   'Dataset': fname}\n",
        "\n",
        "        ResDF = pd.concat([ResDF, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "        for i in range(len(mcc_scores)):\n",
        "            new_row = {'Classifier': name,\n",
        "                       'Accuracy': np.round(acc_scores[i], 2),\n",
        "                       'Recall': np.round(rec_scores[i], 2),\n",
        "                       'Precision': np.round(pre_scores[i], 2),\n",
        "                       'F1 score': np.round(f1s_scores[i], 2),\n",
        "                       'AUC': np.round(auc_scores[i], 2),\n",
        "                       'MCC': np.round(mcc_scores[i], 2),\n",
        "                       'Time': np.round(test_times[i], 2),\n",
        "                       'Dataset': fname}\n",
        "            DetDF = pd.concat([DetDF, pd.DataFrame([new_row])], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "mbuWezMsw72A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8lYnN1EARYf"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "\n",
        "ResDF.to_excel (str(date.today()) + '_SummaryResults.xlsx', header='column_names')\n",
        "DetDF.to_excel (str(date.today()) + '_DetailedResults.xlsx', header='column_names')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}